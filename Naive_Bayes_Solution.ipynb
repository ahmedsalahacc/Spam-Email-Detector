{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Text preprocessing\n",
    "* Decontraction (I'm => I am)\n",
    "* Remove all punctuation, tags, etc.\n",
    "* Convert string into an array of words\n",
    "* Stemming or Lemmatization\n",
    "* Remove stopwords (words that occur a lot such as [I, he, this, there, is, had, ...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hi', 'nice', 'day', 'hope', 'great']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import stopwords and stemmer\n",
    "stopwords_to_remove = stopwords.words('english')\n",
    "stemmer = SnowballStemmer('english')\n",
    "\n",
    "# Decontract abbreviations\n",
    "def decontracted(phrase):\n",
    "    # Special cases\n",
    "    phrase = re.sub(r\"won\\'t\", \"will not\", phrase)\n",
    "    phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\n",
    "\n",
    "    # General cases\n",
    "    phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'re\", \" are\", phrase)\n",
    "    phrase = re.sub(r\"\\'s\", \" is\", phrase)\n",
    "    phrase = re.sub(r\"\\'d\", \" would\", phrase)\n",
    "    phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n",
    "    phrase = re.sub(r\"\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n",
    "    phrase = re.sub(r\"\\'m\", \" am\", phrase)\n",
    "    return phrase\n",
    "\n",
    "\n",
    "def preprocess_text(sentence):\n",
    "    sentence =  decontracted(sentence.lower())# Expand words (I'm to I am) and change all letters to lowercase\n",
    "    sentence =  re.sub(r'[^\\w\\s]','',sentence)# Remove all characters that are not english words\n",
    "    sentence =  nltk.word_tokenize(sentence)# Convert string into an array of words\n",
    "    sentence =  [word for word in sentence if word not in stopwords_to_remove]# Remove stopwords\n",
    "    sentence =  [stemmer.stem(word) for word in sentence]# Stemming\n",
    "    return sentence\n",
    "\n",
    "preprocess_text(\"Hi, this is a nice day isn't it. Hope your are doing great!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the naive bayes classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class naive_bayes():\n",
    "    # takes input the data as a numpy array that contains multiple arrays (same as the number of classes), each contains preprocessed text data belonging to a class. The class is indicated by the index of the array\n",
    "    def __init__(self,data_X, data_y):\n",
    "        self.data_X = data_X\n",
    "        self.data_y = data_y\n",
    "        self.num_classes = 2\n",
    "        self.class_priors = np.zeros(self.num_classes) #[0,0] = [P(not spam),P(spam)]\n",
    "        self.word_dict_likelihood = {}\n",
    "        self.word_dict_total = {}\n",
    "        \n",
    "    def train(self):\n",
    "        # Calculating class priors\n",
    "        self.class_priors[1] = np.sum(self.data_y)/len(self.data_y)\n",
    "        self.class_priors[0] = 1-self.class_priors[1]\n",
    "        \n",
    "        # Calculate word likelihoods\n",
    "        for email,label in tqdm(zip(self.data_X,self.data_y)):\n",
    "            preprocessed_email = preprocess_text(email)\n",
    "            for word in preprocessed_email:\n",
    "                if word not in self.word_dict_total:\n",
    "                    self.word_dict_total[word] = 1\n",
    "                else:\n",
    "                    self.word_dict_total[word] += 1\n",
    "            if label == 1:\n",
    "                for word in preprocessed_email:\n",
    "                    if word not in self.word_dict_likelihood:\n",
    "                        self.word_dict_likelihood[word] = 1\n",
    "                    else:\n",
    "                        self.word_dict_likelihood[word] += 1\n",
    "                    \n",
    "        # Normalize likelihoods\n",
    "        for word in self.word_dict_likelihood:\n",
    "            self.word_dict_likelihood[word] /= self.word_dict_total[word]\n",
    "    \n",
    "    def predict(self,text_to_predict):\n",
    "        # Preprocess given text\n",
    "        preprocessed_email = preprocess_text(text_to_predict)\n",
    "        \n",
    "        # Multiply probabilities for all words and apply bayes rule\n",
    "        P_spam = 1\n",
    "        P_not_spam = 1\n",
    "        for word in preprocessed_email:\n",
    "            if word in self.word_dict_likelihood:\n",
    "                P_b_a = self.word_dict_likelihood[word]\n",
    "                P_b_not_a = 1 - P_b_a\n",
    "                P_spam *= P_b_a\n",
    "                P_not_spam *= P_b_not_a\n",
    "        \n",
    "        P_spam *= self.class_priors[1]\n",
    "        P_not_spam *= self.class_priors[0]\n",
    "        if P_spam > P_not_spam:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read, explore, and prepare our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1961</th>\n",
       "      <td>Subject: telephone interview with the houston ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5304</th>\n",
       "      <td>Subject: entouch newsletter  business highligh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4891</th>\n",
       "      <td>Subject: free two week ft - online trial  - - ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4919</th>\n",
       "      <td>Subject: re : fw : energy book promotion  juli...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2182</th>\n",
       "      <td>Subject: re : fw : energy book promotion  than...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  spam\n",
       "1961  Subject: telephone interview with the houston ...     0\n",
       "5304  Subject: entouch newsletter  business highligh...     0\n",
       "4891  Subject: free two week ft - online trial  - - ...     0\n",
       "4919  Subject: re : fw : energy book promotion  juli...     0\n",
       "2182  Subject: re : fw : energy book promotion  than...     0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"emails.csv\")\n",
    "df = df.reindex(np.random.permutation(df.index))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = df[:5300]\n",
    "test_data = df[5300:]\n",
    "training_x = training_data[\"text\"]\n",
    "training_y = training_data[\"spam\"]\n",
    "testing_x = test_data[\"text\"]\n",
    "testing_y = test_data[\"spam\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create our model,train, and test it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5300it [00:15, 344.70it/s]\n"
     ]
    }
   ],
   "source": [
    "naive_bayes_classifier = naive_bayes(training_x,training_y)\n",
    "naive_bayes_classifier.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 428/428 [00:01<00:00, 350.03it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8995327102803738"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "preds = []\n",
    "for text in tqdm(testing_x):\n",
    "    prediction = naive_bayes_classifier.predict(text)\n",
    "    preds.append(prediction)\n",
    "accuracy = accuracy_score(preds,testing_y)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Our naive bayes model achieved 89.9% "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
